name: AI图片视频爬虫

on:
  schedule:
    - cron: '0 2 * * *'  # 每天UTC时间2点运行（北京时间10点）
  workflow_dispatch:      # 允许手动触发

jobs:
  crawl-ai-videos:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: 检出代码
      uses: actions/checkout@v4
      
    - name: 设置Python环境
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: 安装系统依赖
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libnss3 \
          libnspr4 \
          libatk1.0-0 \
          libatk-bridge2.0-0 \
          libcups2 \
          libdrm2 \
          libxkbcommon0 \
          libxcomposite1 \
          libxdamage1 \
          libxrandr2 \
          libgbm1 \
          libxss1 \
          libgtk-3-0 \
          libasound2 \
          libgl1
        
    - name: 安装Python依赖
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: 安装Playwright浏览器
      run: |
        python -m playwright install
        python -m playwright install-deps
        
    - name: 执行AI图片视频爬虫
      run: python run_bilibili.py
      
    - name: 上传爬取数据
      uses: actions/upload-artifact@v4
      with:
        name: ai-video-data-$(date +%Y%m%d)
        path: |
          *.json
          crawled_data.json
        retention-days: 90
        
    - name: 提交去重数据库
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add crawled_data.json
        git commit -m "Update crawl deduplication database [skip ci]" || exit 0
        git push
